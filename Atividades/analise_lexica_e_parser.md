# 1. Princ√≠pio do Match Mais Longo (Maximal Munch)

O **princ√≠pio do match mais longo**, tamb√©m conhecido como *longest match*, √© uma regra utilizada em **an√°lise l√©xica** para resolver ambiguidades na identifica√ß√£o de tokens.  

Segundo este princ√≠pio, o **scanner (lexer)** deve sempre reconhecer o **maior lexema poss√≠vel** que corresponde a uma determinada express√£o regular, antes de tentar formar outros tokens menores.

### üß© Exemplo

Considere a entrada: >=.


Sem o princ√≠pio do match mais longo, o lexer poderia reconhecer `>` e depois `=` como dois tokens separados.  
Aplicando o princ√≠pio, o lexer reconhece `>=` como um **√∫nico token** de operador relacional.

Essa regra garante que o c√≥digo fonte seja tokenizado de forma **consistente** e **sem ambiguidades**.

---

# 2. Estrutura do Token

Um **token** √© a menor unidade significativa de um programa que o analisador sint√°tico (*parser*) pode processar.

Cada token possui uma estrutura b√°sica composta por:

- **Lexema:** o texto original do programa que representa o token.  
- **Tipo:** a categoria do token (ex.: palavra-chave, identificador, n√∫mero, operador).  
- **Linha e coluna:** a posi√ß√£o do token no c√≥digo fonte, usada para mensagens de erro ou depura√ß√£o.

---

# 3. Bufferiza√ß√£o

A **bufferiza√ß√£o** √© a t√©cnica utilizada pelo lexer para ler o c√≥digo fonte de forma eficiente, controlando a leitura por blocos em vez de processar caractere por caractere sem controle.

Geralmente, o lexer mant√©m um **buffer de entrada**, que armazena uma por√ß√£o do c√≥digo fonte que ser√° analisada.  
O buffer permite **‚Äúvoltar‚Äù e ‚Äúavan√ßar‚Äù** quando o lexer precisa decidir qual token √© o mais longo que casa.

Essa t√©cnica √© essencial para implementar corretamente o princ√≠pio do *match mais longo*, pois o lexer precisa **olhar √† frente** para decidir se deve continuar formando um token maior.

---

# 4. Integra√ß√£o com An√°lise Sint√°tica

Ap√≥s a gera√ß√£o dos tokens pelo lexer, o **parser (analisador sint√°tico)** consome esses tokens para construir uma **estrutura hier√°rquica do programa**, que geralmente √© uma **√°rvore sint√°tica abstrata (AST)**.

O parser **n√£o l√™ o c√≥digo fonte diretamente**, mas sim os tokens gerados pelo lexer.  

Cada token fornece informa√ß√µes detalhadas (*tipo, lexema, posi√ß√£o*) que o parser usa para verificar a **gram√°tica da linguagem**.  

Caso o parser encontre uma sequ√™ncia de tokens que n√£o corresponde √† gram√°tica, ele gera um **erro sint√°tico** indicando a posi√ß√£o do problema.

---

## üíª C√ìDIGO (Exemplo em Java)

```java
import java.util.*;
import java.util.regex.*;

class Token {
    String lexema;
    String tipo;
    int linha;
    int coluna;

    public Token(String lexema, String tipo, int linha, int coluna) {
        this.lexema = lexema;
        this.tipo = tipo;
        this.linha = linha;
        this.coluna = coluna;
    }

    @Override
    public String toString() {
        return String.format("%-15s | %-15s (linha %d, col %d)", lexema, tipo, linha, coluna);
    }
}

class Lexer {
    private final LinkedHashMap<Pattern, String> regras = new LinkedHashMap<>();
    private final List<Token> tokens = new ArrayList<>();
    private final List<String> erros = new ArrayList<>();

    public Lexer() {
        // Palavras-chave
        regras.put(Pattern.compile("^(Programa|Armazene|Guarde|mut√°vel|Inteiro|Se|Ent√£o|Sen√£o|Fim|ParaCada|Imprima|leia_entrada|para_inteiro)"), "PALAVRA_CHAVE");
        // Operadores l√≥gicos
        regras.put(Pattern.compile("^(E|Ou|N√£o)"), "OP_LOGICO");
        // Identificadores
        regras.put(Pattern.compile("^([a-z][a-zA-Z0-9]*|_[a-z0-9_]+)"), "IDENTIFICADOR");
        // N√∫meros inteiros
        regras.put(Pattern.compile("^(\\d+)"), "NUMERO");
        // Strings
        regras.put(Pattern.compile("^\"(?:[^\"\\\\]|\\\\.)*\""), "STRING");
        // Operadores relacionais
        regras.put(Pattern.compile("^(==|!=|<=|>=|<|>)"), "OP_REL");
        // Operadores aritm√©ticos
        regras.put(Pattern.compile("^[+\\-*/]"), "OP_ARIT");
        // Delimitadores
        regras.put(Pattern.compile("^[\\[\\]\\(\\)\\{\\},:]"), "DELIMITADOR");
        // Espa√ßos e coment√°rios (ignorar)
        regras.put(Pattern.compile("^\\s+"), "IGNORADO");
        regras.put(Pattern.compile("^#.*"), "IGNORADO");
    }

    public void analisar(String codigo) {
        String[] linhas = codigo.split("\n");
        int linhaNum = 1;

        for (String linha : linhas) {
            int coluna = 1;
            String buffer = linha;

            while (!buffer.isEmpty()) {
                boolean reconhecido = false;
                Token tokenMaisLongo = null;

                // MAXIMAL MUNCH: procura o token mais longo que casa
                for (var entry : regras.entrySet()) {
                    Matcher m = entry.getKey().matcher(buffer);
                    if (m.find()) {
                        String lexema = m.group();

                        if (tokenMaisLongo == null || lexema.length() > tokenMaisLongo.lexema.length()) {
                            tokenMaisLongo = new Token(lexema, entry.getValue(), linhaNum, coluna);
                        }
                    }
                }

                if (tokenMaisLongo != null) {
                    if (!tokenMaisLongo.tipo.equals("IGNORADO")) {
                        tokens.add(tokenMaisLongo);
                    }
                    buffer = buffer.substring(tokenMaisLongo.lexema.length());
                    coluna += tokenMaisLongo.lexema.length();
                    reconhecido = true;
                }

                if (!reconhecido) {
                    char c = buffer.charAt(0);
                    erros.add("Erro l√©xico na linha " + linhaNum + ", coluna " + coluna + ": caractere inv√°lido '" + c + "'");
                    buffer = buffer.substring(1);
                    coluna++;
                }
            }

            linhaNum++;
        }
    }

    public List<Token> getTokens() { return tokens; }
    public List<String> getErros() { return erros; }

    public void imprimirTokens() { tokens.forEach(System.out::println); }
    public void imprimirErros() { 
        if (!erros.isEmpty()) { 
            System.out.println("\n=== ERROS L√âXICOS ==="); 
            erros.forEach(System.out::println); 
        } 
    }
}

// Parser simples de demonstra√ß√£o
class Parser {
    private final List<Token> tokens;
    private int pos = 0;

    public Parser(List<Token> tokens) {
        this.tokens = tokens;
    }

    private Token peek() { return pos < tokens.size() ? tokens.get(pos) : null; }
    private Token next() { return pos < tokens.size() ? tokens.get(pos++) : null; }

    // Exemplo: reconhece uma declara√ß√£o simples: PALAVRA_CHAVE IDENTIFICADOR '=' NUMERO
    public void analisar() {
        while (peek() != null) {
            Token t = next();
            if (t.tipo.equals("PALAVRA_CHAVE") && t.lexema.equals("Inteiro")) {
                Token id = next();
                Token op = next();
                Token num = next();

                if (id != null && id.tipo.equals("IDENTIFICADOR") &&
                    op != null && op.lexema.equals("=") &&
                    num != null && num.tipo.equals("NUMERO")) {

                    System.out.println("Declara√ß√£o v√°lida: " + id.lexema + " = " + num.lexema);
                } else {
                    System.out.println("Erro sint√°tico pr√≥ximo de linha " + t.linha);
                }
            }
        }
    }
}

// Testando
public class Main {
    public static void main(String[] args) {
        String codigo = """
        Inteiro x = 10
        Se x <= 10 Ent√£o
            Imprima "Voc√™ venceu"
        Fim
        # coment√°rio
        """;

        Lexer lexer = new Lexer();
        lexer.analisar(codigo);

        System.out.println("=== TOKENS ===");
        lexer.imprimirTokens();
        lexer.imprimirErros();

        System.out.println("\n=== PARSER ===");
        Parser parser = new Parser(lexer.getTokens());
        parser.analisar();
    }
}


