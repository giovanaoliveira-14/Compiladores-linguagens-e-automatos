# 1. Princ√≠pio do Match Mais Longo (Maximal Munch)

O **princ√≠pio do match mais longo**, tamb√©m conhecido como *longest match*, √© uma regra utilizada em **an√°lise l√©xica** para resolver ambiguidades na identifica√ß√£o de tokens.  

Segundo este princ√≠pio, o **scanner (lexer)** deve sempre reconhecer o **maior lexema poss√≠vel** que corresponde a uma determinada express√£o regular, antes de tentar formar outros tokens menores.

### üß© Exemplo

Considere a entrada: >=.


Sem o princ√≠pio do match mais longo, o lexer poderia reconhecer `>` e depois `=` como dois tokens separados.  
Aplicando o princ√≠pio, o lexer reconhece `>=` como um **√∫nico token** de operador relacional.

Essa regra garante que o c√≥digo fonte seja tokenizado de forma **consistente** e **sem ambiguidades**.

---

# 2. Estrutura do Token

Um **token** √© a menor unidade significativa de um programa que o analisador sint√°tico (*parser*) pode processar.

Cada token possui uma estrutura b√°sica composta por:

- **Lexema:** o texto original do programa que representa o token.  
- **Tipo:** a categoria do token (ex.: palavra-chave, identificador, n√∫mero, operador).  
- **Linha e coluna:** a posi√ß√£o do token no c√≥digo fonte, usada para mensagens de erro ou depura√ß√£o.

---

# 3. Bufferiza√ß√£o

A **bufferiza√ß√£o** √© a t√©cnica utilizada pelo lexer para ler o c√≥digo fonte de forma eficiente, controlando a leitura por blocos em vez de processar caractere por caractere sem controle.

Geralmente, o lexer mant√©m um **buffer de entrada**, que armazena uma por√ß√£o do c√≥digo fonte que ser√° analisada.  
O buffer permite **‚Äúvoltar‚Äù e ‚Äúavan√ßar‚Äù** quando o lexer precisa decidir qual token √© o mais longo que casa.

Essa t√©cnica √© essencial para implementar corretamente o princ√≠pio do *match mais longo*, pois o lexer precisa **olhar √† frente** para decidir se deve continuar formando um token maior.

---

# 4. Integra√ß√£o com An√°lise Sint√°tica

Ap√≥s a gera√ß√£o dos tokens pelo lexer, o **parser (analisador sint√°tico)** consome esses tokens para construir uma **estrutura hier√°rquica do programa**, que geralmente √© uma **√°rvore sint√°tica abstrata (AST)**.

O parser **n√£o l√™ o c√≥digo fonte diretamente**, mas sim os tokens gerados pelo lexer.  

Cada token fornece informa√ß√µes detalhadas (*tipo, lexema, posi√ß√£o*) que o parser usa para verificar a **gram√°tica da linguagem**.  

Caso o parser encontre uma sequ√™ncia de tokens que n√£o corresponde √† gram√°tica, ele gera um **erro sint√°tico** indicando a posi√ß√£o do problema.

---

## üíª C√ìDIGO (Exemplo em Java)

```java
import java.util.*;
import java.util.regex.*;

class Token {
    String lexema;
    String tipo;
    int linha;
    int coluna;

    public Token(String lexema, String tipo, int linha, int coluna) {
        this.lexema = lexema;
        this.tipo = tipo;
        this.linha = linha;
        this.coluna = coluna;
    }

    @Override
    public String toString() {
        return String.format("%-15s | %-15s (linha %d, col %d)", 
                lexema, tipo, linha, coluna);
    }
}

class Lexer {
    private final LinkedHashMap<Pattern, String> regras = new LinkedHashMap<>();
    private final List<Token> tokens = new ArrayList<>();
    private final List<String> erros = new ArrayList<>();

    public Lexer() {
        regras.put(Pattern.compile("^(Programa|Armazene|Guarde|mut√°vel|Inteiro|Se|Ent√£o|Sen√£o|Fim|ParaCada|Imprima|leia_entrada|para_inteiro)"), "PALAVRA_CHAVE");
        regras.put(Pattern.compile("^(E|Ou|N√£o)"), "OP_LOGICO");
        regras.put(Pattern.compile("^([a-z][a-zA-Z0-9]*|_[a-z0-9_]+)"), "IDENTIFICADOR");
        regras.put(Pattern.compile("^(\\d+)"), "NUMERO");
        regras.put(Pattern.compile("^\"(?:[^\"\\\\]|\\\\.)*\""), "STRING");
        regras.put(Pattern.compile("^(==|!=|<=|>=|<|>)"), "OP_REL");
        regras.put(Pattern.compile("^[+\\-*/]"), "OP_ARIT");
        regras.put(Pattern.compile("^[\\[\\]\\(\\)\\{\\},:]"), "DELIMITADOR");
        regras.put(Pattern.compile("^\\s+"), "IGNORADO");
        regras.put(Pattern.compile("^#.*"), "IGNORADO");
    }

    public void analisar(String codigo) {
        String[] linhas = codigo.split("\n");
        int linhaNum = 1;

        for (String linha : linhas) {
            int coluna = 1;
            String buffer = linha;

            while (!buffer.isEmpty()) {
                boolean reconhecido = false;
                Token tokenMaisLongo = null;

                for (var entry : regras.entrySet()) {
                    Matcher m = entry.getKey().matcher(buffer);
                    if (m.find()) {
                        String lexema = m.group();

                        if (tokenMaisLongo == null || lexema.length() > tokenMaisLongo.lexema.length()) {
                            tokenMaisLongo = new Token(lexema, entry.getValue(), linhaNum, coluna);
                        }
                    }
                }

                if (tokenMaisLongo != null) {
                    if (!tokenMaisLongo.tipo.equals("IGNORADO")) {
                        tokens.add(tokenMaisLongo);
                    }
                    buffer = buffer.substring(tokenMaisLongo.lexema.length());
                    coluna += tokenMaisLongo.lexema.length();
                    reconhecido = true;
                }

                if (!reconhecido) {
                    char c = buffer.charAt(0);
                    erros.add("Erro l√©xico na linha " + linhaNum + ", coluna " + coluna + ": caractere inv√°lido '" + c + "'");
                    buffer = buffer.substring(1);
                    coluna++;
                }
            }

            linhaNum++;
        }
    }

    public List<Token> getTokens() { return tokens; }
    public List<String> getErros() { return erros; }

    public void imprimirTokens() { tokens.forEach(System.out::println); }
    public void imprimirErros() {
        if (!erros.isEmpty()) {
            System.out.println("\n=== ERROS L√âXICOS ===");
            erros.forEach(System.out::println);
        }
    }
}


class Node {
    String tipo;
    List<Node> filhos = new ArrayList<>();

    public Node(String tipo) {
        this.tipo = tipo;
    }

    public void addFilho(Node n) {
        filhos.add(n);
    }

    public void imprimir(String indent) {
        System.out.println(indent + tipo);
        for (Node f : filhos) {
            f.imprimir(indent + "  ");
        }
    }
}

class Parser {
    private final List<Token> tokens;
    private int pos = 0;

    public Parser(List<Token> tokens) {
        this.tokens = tokens;
    }

    private Token peek() {
        return pos < tokens.size() ? tokens.get(pos) : null;
    }

    private Token next() {
        return pos < tokens.size() ? tokens.get(pos++) : null;
    }

    public Node analisar() {
        Node raiz = new Node("Programa");

        while (peek() != null) {
            Token t = peek();

            if (t.lexema.equals("Inteiro")) {
                raiz.addFilho(parseDeclaracao());
            }
            else if (t.lexema.equals("Se")) {
                raiz.addFilho(parseIf());
            }
            else {
                next(); // Ignora tokens inesperados
            }
        }

        return raiz;
    }

    private Node parseDeclaracao() {
        Token tipo = next();
        Token id = next();
        Token op = next();
        Token num = next();

        Node decl = new Node("Declara√ß√£o");
        decl.addFilho(new Node("Tipo: " + tipo.lexema));
        decl.addFilho(new Node("Identificador: " + id.lexema));

        Node atrib = new Node("Atribui√ß√£o");
        atrib.addFilho(new Node("N√∫mero: " + num.lexema));

        decl.addFilho(atrib);

        return decl;
    }

    private Node parseIf() {
        next(); // "Se"

        Token id = next();
        Token op = next();
        Token num = next();
        Token entao = next();

        Node noIf = new Node("Se");

        Node cond = new Node("Condi√ß√£o");
        cond.addFilho(new Node("Identificador: " + id.lexema));
        cond.addFilho(new Node("Operador: " + op.lexema));
        cond.addFilho(new Node("N√∫mero: " + num.lexema));

        noIf.addFilho(cond);

        Node corpo = new Node("Corpo");
        while (peek() != null && !peek().lexema.equals("Fim")) {
            if (peek().lexema.equals("Imprima")) {
                corpo.addFilho(parseImprima());
            } else {
                next();
            }
        }

        if (peek() != null && peek().lexema.equals("Fim")) next();

        noIf.addFilho(corpo);
        return noIf;
    }

    private Node parseImprima() {
        next(); // Imprimir
        Token str = next();

        Node n = new Node("Imprima");
        n.addFilho(new Node("String: " + str.lexema));

        return n;
    }
}

public class Main {
    public static void main(String[] args) {
        String codigo = """
        Inteiro x = 10
        Se x <= 10 Ent√£o
            Imprima "Voc√™ venceu"
        Fim
        # coment√°rio
        """;

        Lexer lexer = new Lexer();
        lexer.analisar(codigo);

        System.out.println(" TOKENS");
        lexer.imprimirTokens();
        lexer.imprimirErros();

        Parser parser = new Parser(lexer.getTokens());
        Node arvore = parser.analisar();

        System.out.println("\n √ÅRVORE SINT√ÅTICA");
        arvore.imprimir("");
    }
}



